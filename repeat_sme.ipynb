{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77405f56-55dd-4e76-baa4-fe14f43d592c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading modules\n",
      "loading modules\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/radrogue/.conda/envs/environmentname/lib/python3.7/site-packages/ptsa/data/readers/__init__.py:19: FutureWarning: PTSA readers will be removed in a future release. Please consider using the cmlreaders package instead: https://github.com/pennmem/cmlreaders\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "print(\"loading modules\")\n",
    "import os\n",
    "from time import time\n",
    "import csv\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "# import xarray as xr\n",
    "# import scipy.stats as stats\n",
    "# import scipy.spatial as spatial\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# import mne\n",
    "# from mne import channels\n",
    "# from mne import time_frequency\n",
    "\n",
    "# import h5py\n",
    "\n",
    "# import glob\n",
    "# # from psifr import fr\n",
    "\n",
    "# import ptsa \n",
    "# #from ptsa.data.TimeSeriesX import TimeSeries\n",
    "# from ptsa.data.timeseries import TimeSeries\n",
    "# from ptsa.data import timeseries\n",
    "# from ptsa.data.readers import BaseEventReader\n",
    "\n",
    "# from ptsa.data.filters import MorletWaveletFilter\n",
    "# from ptsa.data.filters import ButterworthFilter\n",
    "import cmlreaders as cml\n",
    "from repeat_sme import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c715e288-f8f2-48e2-bb8c-227f341d0780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_powers(subject):\n",
    "    bad = []\n",
    "    data = cml.get_data_index(kind = 'r1'); data = data[data['experiment'] == 'RepFR1']\n",
    "    sessions = data[data.subject == subject].session.unique()\n",
    "    freqs = np.logspace(np.log10(3),np.log10(180), 24)\n",
    "    for sess in sessions:\n",
    "        try:\n",
    "            print(subject, sess, 'loading...')\n",
    "            r = cml.CMLReader(subject=subject, experiment='RepFR1', session=sess)\n",
    "            evs = r.load('task_events')\n",
    "\n",
    "            word = evs.query(\"type == 'WORD'\")\n",
    "            # word = word[word.list != 0]\n",
    "            word = word[word.list != -999]\n",
    "            word.list.unique()\n",
    "            print(subject, sess, 'filtering...')\n",
    "            f, o, n = filter_repetitions(word, word.list.unique()[1:])\n",
    "            # get_raw_eeg(subject, session)\n",
    "            pairs = r.load(\"pairs\")\n",
    "\n",
    "            filtered = pairs[(pairs[\"mni.region\"].str.contains(\"temporal\")) & pairs['mni.region'].\n",
    "                            str.contains('Left')]\n",
    "\n",
    "            eeg = r.load_eeg(scheme=filtered)\n",
    "            channels = eeg.channels\n",
    "\n",
    "            rel_start = 0/1000\n",
    "            rel_stop = 1600/1000\n",
    "            wave_number = 5\n",
    "            half_wav = ((1000 / freqs.min()) * wave_number) * 0.5\n",
    "            sr = float(eeg.samplerate)\n",
    "\n",
    "            buffer_ms = (wave_number * (1000/freqs[0])) / 2\n",
    "            buffer_samp = int(np.ceil(buffer_ms * (sr/1000.)))\n",
    "            buffer_minimized = buffer_ms/1000\n",
    "            path = '/scratch/radrogue/RepFR/{}/sme_pow_debug/session_{}/'.format(subject,sess)\n",
    "            ep, enc_x, mne_evs = Create_Epoch(eeg.to_mne(), f, rel_start + (-1 * buffer_minimized), rel_stop + buffer_minimized)\n",
    "\n",
    "            enc_eeg = ButterworthFilter(freq_range =[58., 62.], filt_type = 'stop', order = 4).filter(enc_x)\n",
    "            print(subject, sess, 'calculating powers...')\n",
    "            Channel_Powers(subject = subject, session = sess, channels_list = channels, eeg=enc_eeg, buffer_samp=buffer_samp, wave_number = wave_number, freqs=freqs, path=path, error_log_path = '', log = True)\n",
    "        except Exception as e:\n",
    "            bad.append(subject+str(sess))\n",
    "    return bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed5f607e-a603-4868-8407-101d0c15a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cml.get_data_index(kind = 'r1'); data = data[data['experiment'] == 'RepFR1']\n",
    "\n",
    "contacts = []\n",
    "\n",
    "for subject, df in data.groupby('subject'):\n",
    "    for session in pd.unique(df['session']):\n",
    "        r = cml.CMLReader(subject=subject, experiment='RepFR1', session=session)\n",
    "        temp = r.load('contacts')\n",
    "        temp['subject'] = pd.Series(subject, index=temp.index)\n",
    "        temp['session'] = pd.Series(session, index=temp.index)\n",
    "        contacts.append(temp)\n",
    "contacts = pd.concat(contacts)\n",
    "regions = ['temporal', 'frontal', 'parietal', 'amygdala', 'Hippocampus']\n",
    "hemispheres = ['Right', 'Left', '']\n",
    "\n",
    "results = pd.DataFrame(columns=['region', 'subjects'])\n",
    "for h in hemispheres:\n",
    "    for r in regions:    \n",
    "        n = contacts[(contacts['mni.region'].str.contains(r)) & contacts['mni.region'].\n",
    "                     str.contains(h)].subject.unique()\n",
    "        results = results.append(pd.DataFrame(dict(region = h +' ' + r, subjects = [n]), index = [len(results)]))\n",
    "# LTL = results[(results.hemisphere == 'Left') & (results.region == 'temporal')]\n",
    "\n",
    "index = get_data_index('r1')\n",
    "LTL_subs = results[results.region == 'Left temporal'].subjects.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3643dbf9-217c-44ec-9b46-86fca741e502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/radrogue/.local/lib/python3.7/site-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.\n",
      "  from distributed.utils import tmpfile\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-68929432f693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCMLDask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_completed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "import CMLDask\n",
    "from dask.distributed import wait, as_completed, progress\n",
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a75890c-5b46-4127-a993-d01155816a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique port for radrogue is 51417\n",
      "{'dashboard_address': ':51417'}\n",
      "To view the dashboard, run: \n",
      "`ssh -fN radrogue@rhino2.psych.upenn.edu -L 8000:192.168.86.142:51417` in your local computer's terminal (NOT rhino) \n",
      "and then navigate to localhost:8000 in your browser\n"
     ]
    }
   ],
   "source": [
    "client = CMLDask.new_dask_client(\"iEEG_power\", \"10GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58c41332-e034-41e1-bd13-2b2546f8432f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "concurrent.futures._base.CancelledError\n"
     ]
    }
   ],
   "source": [
    "futures = client.map(get_powers, LTL_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d48fd04-5f69-488b-ae10-07f7f717331d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c8e6ebacb7404cbc8b118f77f5809e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23bc046-0f10-498d-a45d-1d885e9338a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f63cc6b-6b38-4496-9d33-c520ceec8358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [],\n",
       " [1],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [0, 1, 2, 3, 4, 5],\n",
       " [],\n",
       " [],\n",
       " [3],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad4c1209-1567-4b57-bc78-1bf47e6002b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "concurrent.futures._base.CancelledError\n"
     ]
    }
   ],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f8f0958-57b2-48ea-8588-b7db11c731f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "data = cml.get_data_index(kind = 'r1'); data = data[data['experiment'] == 'RepFR1']\n",
    "\n",
    "for subject in data.subject.unique():\n",
    "    sessions = data[data.subject==subject].session.unique()\n",
    "    freqs = np.logspace(np.log10(3),np.log10(180), 24)\n",
    "    for sess in sessions:\n",
    "        try:\n",
    "            print(subject, sess, 'loading...')\n",
    "            r = cml.CMLReader(subject=subject, experiment='RepFR1', session=sess)\n",
    "            evs = r.load('task_events')\n",
    "\n",
    "            word = evs.query(\"type == 'WORD'\")\n",
    "            # word = word[word.list != 0]\n",
    "            word = word[word.list != -999]\n",
    "            word.list.unique()\n",
    "            print(subject, sess, 'filtering...')\n",
    "            f, o, n = filter_repetitions(word, word.list.unique()[1:])\n",
    "            # get_raw_eeg(subject, session)\n",
    "            pairs = r.load(\"pairs\")\n",
    "\n",
    "            filtered = pairs[(pairs[\"mni.region\"].str.contains(\"temporal\")) & pairs['mni.region'].\n",
    "                            str.contains('Left')]\n",
    "\n",
    "            eeg = r.load_eeg(scheme=filtered)\n",
    "            channels = eeg.channels\n",
    "\n",
    "            rel_start = 0/1000\n",
    "            rel_stop = 1600/1000\n",
    "            wave_number = 5\n",
    "            half_wav = ((1000 / freqs.min()) * wave_number) * 0.5\n",
    "            sr = float(eeg.samplerate)\n",
    "\n",
    "            buffer_ms = (wave_number * (1000/freqs[0])) / 2\n",
    "            buffer_samp = int(np.ceil(buffer_ms * (sr/1000.)))\n",
    "            buffer_minimized = buffer_ms/1000\n",
    "            path = '/scratch/radrogue/RepFR/{}/sme_pow_debug/session_{}/'.format(subject,sess)\n",
    "            ep, enc_x, mne_evs = Create_Epoch(eeg.to_mne(), f, rel_start + (-1 * buffer_minimized), rel_stop + buffer_minimized)\n",
    "\n",
    "            enc_eeg = ButterworthFilter(freq_range =[58., 62.], filt_type = 'stop', order = 4).filter(enc_x)\n",
    "            print(subject, sess, 'calculating powers...')\n",
    "            Channel_Powers(subject = subject, session = sess, channels_list = channels, eeg=enc_eeg, buffer_samp=buffer_samp, wave_number = wave_number, freqs=freqs, path=path, error_log_path = '', log = True)\n",
    "        except Exception as e:\n",
    "            print(subject, sess, 'failed:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c58ad36c-420a-43e3-a436-16ea05561373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_repetitions(events, list_index):\n",
    "\n",
    "    '''\n",
    "    two functions that split recall events that contain repeated word presentations into a new events dataframe containing only \n",
    "    the first and second presentation of repeated words. Then additionally outputs two masks to additionally filter the already filtered \n",
    "    recalls by either their first and second presentation.\n",
    "\n",
    "    This is to ideally split first/second presentations by recalled and not-recalled to calculate two different SMEs\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    events: encoding events ideally from ltpRepFR and a similar repeated word presentation experiment \n",
    "\n",
    "    list_index: list of all list values (in ltpepFr 1 through 25)\n",
    "\n",
    "    Return\n",
    "    -------\n",
    "\n",
    "    filtered_events: events that have one time presented words and the third presentation of repeated words removed \n",
    "\n",
    "    first: array mask to only include the first presentation of filtered repeated encoding events \n",
    "\n",
    "    second: array mask to only include the second presentation of filtered repeated encoding events \n",
    "\n",
    "    '''\n",
    "\n",
    "    def pull_first_and_second_rep_presentations(events, list_index):\n",
    "\n",
    "\n",
    "        '''\n",
    "        take in events and list_index structure from ltpRepFR data, filter events to only include first and second presentation of \n",
    "        second and three times repeated words -- excluding practice list (list 0) and all single presentation words \n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        events: ltpRepFR word events \n",
    "\n",
    "        list_index: list of all list values (in ltpRepFr 1 through 25)\n",
    "\n",
    "        Return\n",
    "        -------\n",
    "        event_mask: array of True and False values for all events -- True events are those that are 2 or 3 times repeated words and only their first and second presentations \n",
    "        '''\n",
    "\n",
    "\n",
    "        session_array = []\n",
    "        session_array.extend(np.repeat(False, 27))\n",
    "\n",
    "        for l in list_index:\n",
    "            current_list = events[events['list'] == l] #interate one list at a time \n",
    "            non_repeat = list(current_list[current_list['repeats'] == 1].item_name)\n",
    "\n",
    "            #dict to track number of presentations of a word during one list \n",
    "            pres_dict = {}\n",
    "            for x in np.unique(current_list.item_name):\n",
    "                pres_dict['{0}'.format(x)] = 0\n",
    "\n",
    "            for word in current_list.item_name:\n",
    "\n",
    "                #if a once repeated word -- append False value and increment that word by 1 presentation \n",
    "                if word in non_repeat:\n",
    "                    session_array.append(False)\n",
    "                    pres_dict[str(word)] += 1 \n",
    "\n",
    "                elif word not in non_repeat:\n",
    "                    #presentation value \n",
    "                    presentation = pres_dict[str(word)]\n",
    "\n",
    "                    #if word has reached or is reaching second presentation -- append True value and increment that word by 1 presentation \n",
    "                    if presentation <= 2:\n",
    "                        session_array.append(True) \n",
    "                        pres_dict[str(word)] += 1 \n",
    "\n",
    "                    elif presentation > 2:\n",
    "                        session_array.append(False)\n",
    "                        pres_dict[str(word)] += 1 \n",
    "\n",
    "        event_mask = np.asarray(session_array).flatten()\n",
    "\n",
    "        if event_mask.shape[0] != 567: \n",
    "            print(\"missing \"+str(567 - int(np.asarray(session_array).shape[0]))+' encoding events. Not Complete.')\n",
    "\n",
    "        return event_mask\n",
    "\n",
    "\n",
    "\n",
    "    def split_first_and_second_pres_events(events, list_index):\n",
    "        '''\n",
    "        After removing single presentation words and the third presentation of repeated words, \n",
    "        specifically split the results encoding event array by first and second presentations and create respective masks \n",
    "\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        events: filtered events from \"pull_first_and_second_rep_presentation function\"\n",
    "\n",
    "        list_index: list of all list values (in ltpRepFr 1 through 25)\n",
    "\n",
    "        Return\n",
    "        -------\n",
    "\n",
    "        first_p_mask: mask to filter event array for only the first presentations of repeated words \n",
    "\n",
    "        second_p_masl: mask to filter event array for only the second presentations of repeated words \n",
    "        '''\n",
    "\n",
    "        first_p = []\n",
    "\n",
    "        for l in list_index:\n",
    "            current_list = events[events['list'] == l]\n",
    "\n",
    "            pres_dict = {}\n",
    "            for x in np.unique(current_list.item_name):\n",
    "                pres_dict['{0}'.format(x)] = 0\n",
    "\n",
    "            for word in current_list.item_name:\n",
    "                presentation = pres_dict[str(word)]\n",
    "\n",
    "                if presentation < 1:\n",
    "                    first_p.append(True)\n",
    "                    pres_dict[str(word)] += 1 \n",
    "\n",
    "                elif presentation >= 1:\n",
    "                    first_p.append(False)\n",
    "                    pres_dict[str(word)] += 1 \n",
    "\n",
    "\n",
    "        first_p_mask = np.asarray(first_p)\n",
    "        second_p_mask = ~first_p_mask\n",
    "\n",
    "\n",
    "        return first_p_mask, second_p_mask \n",
    "\n",
    "    event_mask = pull_first_and_second_rep_presentations(events, list_index)\n",
    "    print(len(events))\n",
    "    filtered_events = events[event_mask]\n",
    "    first, second = split_first_and_second_pres_events(filtered_events, list_index)\n",
    "\n",
    "    return filtered_events, first, second "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1f14d87-4cc7-4bc5-9bb0-c9ce4214fdd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_numpy(array, path, name):\n",
    "\n",
    "        combine = (str(path)+str(name))\n",
    "\n",
    "        np.save( combine , array)\n",
    "\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8be95930-74d9-4957-8d28-be6a2b3d0b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_raw_eeg(subject, sess):\n",
    "#### Change this function\n",
    "\n",
    "\n",
    "        ''' pull raw eeg from ephys directories on rhino -- drop bad channels from bad channel.txt files and compute an average reference + highpass filter  '''\n",
    "\n",
    "\n",
    "        eegpath = '/protocols/r1/subjects/%s/experiments/RepFR1/sessions/%d/ephys/current_processed/' % (subject, sess)\n",
    "\n",
    "        eegfile = glob.glob(eegpath+'*.edf')\n",
    "        if len(eegfile) != 1:\n",
    "            raise Exception(\"Multiple eeg files\")\n",
    "\n",
    "        eegfile = eegfile[0]\n",
    "        print(\"does this try a high-pass??? \")\n",
    "        raw = mne.io.read_raw_edf(eegfile, eog=['EXG1', 'EXG2', 'EXG3', 'EXG4'],\n",
    "                                      misc=['EXG5', 'EXG6', 'EXG7', 'EXG8'],\n",
    "                                      stim_channel='Status',               \n",
    "                                      preload=True) # needs to be true for 0.1Hz high-pass filter to work  \n",
    "\n",
    "#         badchanfile = glob.glob(eegpath+'*_bad_chan*.txt')\n",
    "#         if len(badchanfile) > 0:\n",
    "#             with open(badchanfile[0], 'r') as f:\n",
    "#                 bad = [s.strip() for s in f.readlines()]\n",
    "#             raw.info['bad'] = bad \n",
    "\n",
    "\n",
    "        return raw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61e10223-7fa8-4465-a5d7-325421d254b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Create_Epoch(eeg, events, start, stop):\n",
    "    '''\n",
    "    convert raw eeg to an MNE epoch and then convert to a TimeSeries object for better data manipulation\n",
    "    runs average reference and resamples data\n",
    "    '''\n",
    "    mne_events = np.zeros((len(events), 3), dtype = int)\n",
    "    mne_events[:,0] = [o for i, o in enumerate(events['eegoffset'])]\n",
    "#     print(\"maybe here?\")\n",
    "    ep = mne.Epochs(eeg, mne_events, tmin =  start, tmax = stop, baseline = None, preload = True, on_missing = 'ignore', verbose = False)\n",
    "    ep._data = ep._data * 1000000\n",
    "    ep.set_eeg_reference('average', projection = False)\n",
    "    ep.filter(l_freq = 0.5, h_freq = None, method = 'iir', iir_params = None)\n",
    "    ep.pick_types(eeg= True, exclude = [])\n",
    "    #do  i need this part? maybe not\n",
    "    #ep.resample(500.0)\n",
    "    '''Create an xarray version of epoch data'''\n",
    "    x = TimeSeries(ep._data, dims=('events','channels','time'),\n",
    "                              coords={'events':events.to_records(),\n",
    "                                      'channels':ep.info['ch_names'],\n",
    "                                      'time':ep.times,\n",
    "                                      'samplerate':ep.info['sfreq']})\n",
    "    return ep, x, mne_events\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1de6648a-67a4-4d36-93fb-11e8544a7940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Channel_Powers(subject, session, channels_list, eeg, buffer_samp, wave_number ,freqs, path, error_log_path, log = True):\n",
    "\n",
    "    channels = channels_list\n",
    "\n",
    "    def create_folder(path):\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    for name, i in zip(channels, range(len(channels))):\n",
    "        channel_eeg = eeg[:, i, :]\n",
    "#         print(channel_eeg)\n",
    "#         wave_pows = MorletWaveletFilter(channel_eeg, freqs = freqs, width = wave_number, output = 'power').filter()\n",
    "        wave_pows = MorletWaveletFilter(freqs = freqs, width = wave_number, output = 'power').filter(timeseries = channel_eeg)\n",
    "        wave_pows = wave_pows.data.astype(np.float32)\n",
    "        i_wave_pows = wave_pows[:, :, buffer_samp:-buffer_samp]\n",
    "        if log == True:\n",
    "            i_wave_pows = np.log10(i_wave_pows)\n",
    "        else:\n",
    "            pass \n",
    "\n",
    "        print(str(name)+\" saved.\")\n",
    "\n",
    "        folder = path.format(subject , session)\n",
    "        create_folder(folder)\n",
    "\n",
    "\n",
    "        save_numpy(i_wave_pows,folder, \"{}_{}_mt_logRet_enc_pow_{}\".format(subject ,session, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dba5707-22b4-4d04-88af-9b441644f14c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Grab_Encoding_Power(subj, expmt, sessions, freqs, path, error_log_path, start = .4, stop = .75, wave_number = 5):\n",
    "    subj = subj \n",
    "    expmt = expmt \n",
    "    sessions = sessions \n",
    "    rel_start = start \n",
    "    rel_stop = stop\n",
    "    wave_number = wave_number \n",
    "    freqs = freqs \n",
    "    \n",
    "    #experiment specific params \n",
    "    list_number = 26 \n",
    "    list_index = np.arange(1,26)\n",
    "    \n",
    "    \n",
    "    buffer_ms = (wave_number * (1000/freqs[0])) / 2\n",
    "    sr = 2048.\n",
    "    buffer_samp = int(np.ceil(buffer_ms * (sr/1000.)))\n",
    "    buffer_minimized = buffer_ms/1000\n",
    "    \n",
    "    \n",
    "    path = path \n",
    "    error_log_path = error_log_path \n",
    "    \n",
    "    error_log = []\n",
    "    \n",
    "    print(\"subject: \"+str(subj))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for sess in sessions:\n",
    "        print(\"running session \"+str(sess))\n",
    "        try:\n",
    "            \n",
    "            reader = CMLReader(subj, expmt, sess)\n",
    "            events = reader.load(\"task_events\")\n",
    "            word_evs = events.query(\"type == 'WORD'\")\n",
    "            \n",
    "            print(\"filtering events\")\n",
    "            filtered, first, second = filter_repetitions(word_evs, list_index)\n",
    "            \n",
    "            print(\"loading and processing eeg\")\n",
    "            raw = get_raw_eeg(subj, sess)\n",
    "            epoch, x, mne_events = Create_Epoch(raw, filtered, rel_start+(-1*buffer_minimized), rel_stop+buffer_minimized)\n",
    "            eeg = ButterworthFilter(x, freq_range = [58., 62.], filt_type = 'stop', order = 4).filter()\n",
    "            \n",
    "            print(\"setting channels\")\n",
    "            channels = eeg.channels \n",
    "            channels = np.ndarray.tolist(np.asarray(channels))\n",
    "            \n",
    "            print(\"computing and logging channel power\")\n",
    "            Channel_Powers(subj, sess ,channels, eeg, buffer_samp, wave_number,freqs, path, error_log_path)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"error: \")\n",
    "            print(e)\n",
    "            error_log.append(e)\n",
    "            \n",
    "            \n",
    "    save_numpy(error_log, \"/scratch/brandon.katerman/RepFR/\"+str(subj)+\"/\", 'error_log.txt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0832327-5275-4d8e-8977-d535c66a1572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contact_1</th>\n",
       "      <th>contact_2</th>\n",
       "      <th>label</th>\n",
       "      <th>is_stim_only</th>\n",
       "      <th>type_1</th>\n",
       "      <th>type_2</th>\n",
       "      <th>avg.region</th>\n",
       "      <th>avg.x</th>\n",
       "      <th>avg.y</th>\n",
       "      <th>avg.z</th>\n",
       "      <th>avg.corrected.region</th>\n",
       "      <th>avg.corrected.x</th>\n",
       "      <th>avg.corrected.y</th>\n",
       "      <th>avg.corrected.z</th>\n",
       "      <th>hcp.region</th>\n",
       "      <th>hcp.x</th>\n",
       "      <th>hcp.y</th>\n",
       "      <th>hcp.z</th>\n",
       "      <th>ind.region</th>\n",
       "      <th>ind.x</th>\n",
       "      <th>ind.y</th>\n",
       "      <th>ind.z</th>\n",
       "      <th>ind.corrected.region</th>\n",
       "      <th>ind.corrected.x</th>\n",
       "      <th>ind.corrected.y</th>\n",
       "      <th>ind.corrected.z</th>\n",
       "      <th>mni.region</th>\n",
       "      <th>mni.x</th>\n",
       "      <th>mni.y</th>\n",
       "      <th>mni.z</th>\n",
       "      <th>stein.region</th>\n",
       "      <th>stein.x</th>\n",
       "      <th>stein.y</th>\n",
       "      <th>stein.z</th>\n",
       "      <th>vox.region</th>\n",
       "      <th>vox.x</th>\n",
       "      <th>vox.y</th>\n",
       "      <th>vox.z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>106</td>\n",
       "      <td>107</td>\n",
       "      <td>LB6-LB7</td>\n",
       "      <td>False</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>None</td>\n",
       "      <td>-57.547523</td>\n",
       "      <td>-24.026829</td>\n",
       "      <td>-23.860397</td>\n",
       "      <td>None</td>\n",
       "      <td>-57.547523</td>\n",
       "      <td>-24.026829</td>\n",
       "      <td>-23.860397</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inferiortemporal</td>\n",
       "      <td>-50.37473</td>\n",
       "      <td>-9.19357</td>\n",
       "      <td>-8.830949</td>\n",
       "      <td>None</td>\n",
       "      <td>-50.37473</td>\n",
       "      <td>-9.19357</td>\n",
       "      <td>-8.830949</td>\n",
       "      <td>Left MTG middle temporal gyrus</td>\n",
       "      <td>-57.96460</td>\n",
       "      <td>-15.323450</td>\n",
       "      <td>-17.767224</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>347.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>LB7-LB8</td>\n",
       "      <td>False</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>None</td>\n",
       "      <td>-61.165491</td>\n",
       "      <td>-22.028498</td>\n",
       "      <td>-22.232468</td>\n",
       "      <td>None</td>\n",
       "      <td>-61.165491</td>\n",
       "      <td>-22.028498</td>\n",
       "      <td>-22.232468</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>middletemporal</td>\n",
       "      <td>-55.39343</td>\n",
       "      <td>-8.96442</td>\n",
       "      <td>-7.644324</td>\n",
       "      <td>None</td>\n",
       "      <td>-55.39343</td>\n",
       "      <td>-8.96442</td>\n",
       "      <td>-7.644324</td>\n",
       "      <td>Left MTG middle temporal gyrus</td>\n",
       "      <td>-64.34425</td>\n",
       "      <td>-14.404650</td>\n",
       "      <td>-16.513466</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>356.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>108</td>\n",
       "      <td>109</td>\n",
       "      <td>LB8-LB9</td>\n",
       "      <td>False</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>None</td>\n",
       "      <td>-65.458429</td>\n",
       "      <td>-20.192064</td>\n",
       "      <td>-18.554608</td>\n",
       "      <td>None</td>\n",
       "      <td>-65.458429</td>\n",
       "      <td>-20.192064</td>\n",
       "      <td>-18.554608</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>middletemporal</td>\n",
       "      <td>-60.65673</td>\n",
       "      <td>-8.85612</td>\n",
       "      <td>-6.958573</td>\n",
       "      <td>None</td>\n",
       "      <td>-60.65673</td>\n",
       "      <td>-8.85612</td>\n",
       "      <td>-6.958573</td>\n",
       "      <td>Left STG superior temporal gyrus</td>\n",
       "      <td>-69.08490</td>\n",
       "      <td>-13.489150</td>\n",
       "      <td>-15.001081</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>366.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>116</td>\n",
       "      <td>117</td>\n",
       "      <td>LA6-LA7</td>\n",
       "      <td>False</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>None</td>\n",
       "      <td>-50.777525</td>\n",
       "      <td>-7.999199</td>\n",
       "      <td>-31.863737</td>\n",
       "      <td>None</td>\n",
       "      <td>-50.777525</td>\n",
       "      <td>-7.999199</td>\n",
       "      <td>-31.863737</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inferiortemporal</td>\n",
       "      <td>-46.50273</td>\n",
       "      <td>3.82768</td>\n",
       "      <td>-14.753614</td>\n",
       "      <td>None</td>\n",
       "      <td>-46.50273</td>\n",
       "      <td>3.82768</td>\n",
       "      <td>-14.753614</td>\n",
       "      <td>Left MTG middle temporal gyrus</td>\n",
       "      <td>-52.81985</td>\n",
       "      <td>-2.124035</td>\n",
       "      <td>-27.461274</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>341.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>117</td>\n",
       "      <td>118</td>\n",
       "      <td>LA7-LA8</td>\n",
       "      <td>False</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>None</td>\n",
       "      <td>-53.398891</td>\n",
       "      <td>-10.613172</td>\n",
       "      <td>-29.188873</td>\n",
       "      <td>None</td>\n",
       "      <td>-53.398891</td>\n",
       "      <td>-10.613172</td>\n",
       "      <td>-29.188873</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>middletemporal</td>\n",
       "      <td>-51.43888</td>\n",
       "      <td>4.24743</td>\n",
       "      <td>-15.150680</td>\n",
       "      <td>None</td>\n",
       "      <td>-51.43888</td>\n",
       "      <td>4.24743</td>\n",
       "      <td>-15.150680</td>\n",
       "      <td>Left MTG middle temporal gyrus</td>\n",
       "      <td>-59.57510</td>\n",
       "      <td>-2.748765</td>\n",
       "      <td>-29.158049</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>350.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    contact_1  contact_2    label  is_stim_only type_1 type_2 avg.region  \\\n",
       "83        106        107  LB6-LB7         False      D      D       None   \n",
       "84        107        108  LB7-LB8         False      D      D       None   \n",
       "85        108        109  LB8-LB9         False      D      D       None   \n",
       "92        116        117  LA6-LA7         False      D      D       None   \n",
       "93        117        118  LA7-LA8         False      D      D       None   \n",
       "\n",
       "        avg.x      avg.y      avg.z avg.corrected.region  avg.corrected.x  \\\n",
       "83 -57.547523 -24.026829 -23.860397                 None       -57.547523   \n",
       "84 -61.165491 -22.028498 -22.232468                 None       -61.165491   \n",
       "85 -65.458429 -20.192064 -18.554608                 None       -65.458429   \n",
       "92 -50.777525  -7.999199 -31.863737                 None       -50.777525   \n",
       "93 -53.398891 -10.613172 -29.188873                 None       -53.398891   \n",
       "\n",
       "    avg.corrected.y  avg.corrected.z hcp.region  hcp.x  hcp.y  hcp.z  \\\n",
       "83       -24.026829       -23.860397       None    NaN    NaN    NaN   \n",
       "84       -22.028498       -22.232468       None    NaN    NaN    NaN   \n",
       "85       -20.192064       -18.554608       None    NaN    NaN    NaN   \n",
       "92        -7.999199       -31.863737       None    NaN    NaN    NaN   \n",
       "93       -10.613172       -29.188873       None    NaN    NaN    NaN   \n",
       "\n",
       "          ind.region     ind.x    ind.y      ind.z ind.corrected.region  \\\n",
       "83  inferiortemporal -50.37473 -9.19357  -8.830949                 None   \n",
       "84    middletemporal -55.39343 -8.96442  -7.644324                 None   \n",
       "85    middletemporal -60.65673 -8.85612  -6.958573                 None   \n",
       "92  inferiortemporal -46.50273  3.82768 -14.753614                 None   \n",
       "93    middletemporal -51.43888  4.24743 -15.150680                 None   \n",
       "\n",
       "    ind.corrected.x  ind.corrected.y  ind.corrected.z  \\\n",
       "83        -50.37473         -9.19357        -8.830949   \n",
       "84        -55.39343         -8.96442        -7.644324   \n",
       "85        -60.65673         -8.85612        -6.958573   \n",
       "92        -46.50273          3.82768       -14.753614   \n",
       "93        -51.43888          4.24743       -15.150680   \n",
       "\n",
       "                           mni.region     mni.x      mni.y      mni.z  \\\n",
       "83     Left MTG middle temporal gyrus -57.96460 -15.323450 -17.767224   \n",
       "84     Left MTG middle temporal gyrus -64.34425 -14.404650 -16.513466   \n",
       "85   Left STG superior temporal gyrus -69.08490 -13.489150 -15.001081   \n",
       "92     Left MTG middle temporal gyrus -52.81985  -2.124035 -27.461274   \n",
       "93     Left MTG middle temporal gyrus -59.57510  -2.748765 -29.158049   \n",
       "\n",
       "   stein.region stein.x stein.y stein.z vox.region  vox.x  vox.y  vox.z  \n",
       "83         None    None    None    None       None  347.0  249.0  122.0  \n",
       "84         None    None    None    None       None  356.0  249.0  123.0  \n",
       "85         None    None    None    None       None  366.0  249.0  124.0  \n",
       "92         None    None    None    None       None  341.0  224.0  120.0  \n",
       "93         None    None    None    None       None  350.0  223.0  120.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce36983-0319-4b96-9fc6-0b3fee8fd59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c21a2aa-b2c2-44d2-a59c-c30f67bb0539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea40e7ca-4833-442f-89df-205745ff47e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environmentname",
   "language": "python",
   "name": "environmentname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
