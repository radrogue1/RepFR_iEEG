{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2a5915-c291-4e28-814a-9d8806109658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "'''\n",
    "Created by Brandon Katerman on March 13th, 2022\n",
    "\n",
    "Last Modified: 04/17/22 by Ricardo Adrogue\n",
    "\n",
    "Current stats to run on encoding events for RepFR1 -- successor to sme_tstat.py\n",
    "'''\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "from importlib import reload\n",
    "from cmlreaders import CMLReader, get_data_index \n",
    "# imports all functions needed for this to work\n",
    "import repeat_sme\n",
    "from brain_labels import *\n",
    "import regionalizationModule\n",
    "from brain_labels import *\n",
    "import eeg_check\n",
    "import importlib\n",
    "\n",
    "# import Dask and Dask functions to run script on the cluster\n",
    "import CMLDask\n",
    "from dask.distributed import wait, as_completed, progress\n",
    "from dask import config\n",
    "config.set({'timeouts':{'connect':'90s', 'tcp':'120s'}})\n",
    "# import xmode"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebf45e8d-92c5-40f0-ade0-8c57701a04a5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# makes a list of RepFR1 subjects with electrodes in ROIs\n",
    "data = get_data_index(kind = 'r1'); data = data[data['experiment'] == 'RepFR1']\n",
    "# pulls all contacts from the montage\n",
    "loc = []\n",
    "pairs = []\n",
    "for subject, df in data.groupby('subject'):\n",
    "    for session in pd.unique(df['session']):\n",
    "        r = CMLReader(subject=subject, experiment='RepFR1', session=session)\n",
    "        temp = r.load('localization')\n",
    "        t_p = r.load('pairs')\n",
    "        temp['subject'] = pd.Series(subject, index=temp.index)\n",
    "        temp['session'] = pd.Series(session, index=temp.index)\n",
    "        t_p['subject'] = pd.Series(subject, index=t_p.index)\n",
    "        t_p['session'] = pd.Series(session, index=t_p.index)\n",
    "        loc.append(temp)\n",
    "        pairs.append(t_p)\n",
    "all_loc = pd.concat(loc)\n",
    "all_pairs = pd.concat(pairs)\n",
    "all_loc_p = all_loc.loc['pairs']\n",
    "# loc_p[loc_p['atlases.dk'].]\n",
    "# all_loc_p['atlases.whole_brain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d025972c-1b9e-4b56-9681-b4fe0cba4cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a list of RepFR1 subjects with electrodes in ROIs\n",
    "exp = 'RepFR1'\n",
    "data = get_data_index(kind = 'r1'); data = data[data['experiment'] == exp]\n",
    "# pulls all contacts from the montage\n",
    "loc = []\n",
    "pairs = []\n",
    "evs = []\n",
    "subjects = []\n",
    "sessions = []\n",
    "for subject, df in data.groupby('subject'):\n",
    "    session=df.session.iloc[0]\n",
    "    subjects.append(subject)\n",
    "    sessions.append(session)\n",
    "    r = CMLReader(subject=subject, experiment=exp, session=session)\n",
    "    t_evs = r.load('task_events')\n",
    "    temp = r.load('localization')\n",
    "    temp['subject'] = pd.Series(subject, index=temp.index)\n",
    "    temp['session'] = pd.Series(session, index=temp.index)\n",
    "    evs.append(t_evs)\n",
    "    loc.append(temp)\n",
    "all_loc = pd.concat(loc)\n",
    "all_loc_p = all_loc.loc['pairs']\n",
    "# loc_p[loc_p['atlases.dk'].]\n",
    "# all_loc_p['atlases.whole_brain'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db910b27-65d4-41f3-901e-fb438c22fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_pairs(sub, sess): \n",
    "    # *** Filters out noisy pairs *** #\n",
    "    exp = 'RepFR1'\n",
    "    f_pairs = eeg_check.eeg_check(sub, sess, exp)\n",
    "#     f_pairs['subject'] = pd.Series(sub, index=f_pairs.index)\n",
    "#     f_pairs['session'] = pd.Series(sess, index=f_pairs.index)\n",
    "#     f_pairs = f_pairs[f_pairs.bad == 0]\n",
    "    return f_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52935b06-768a-4f11-a756-ea98c3577fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "refilter = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "421f6e59-64ac-4745-b206-a5d72bf1d3b9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no client\n",
      "Unique port for radrogue is 51417\n",
      "{'dashboard_address': ':51417'}\n",
      "To view the dashboard, run: \n",
      "`ssh -fN radrogue@rhino2.psych.upenn.edu -L 8000:192.168.86.146:51417` in your local computer's terminal (NOT rhino) \n",
      "and then navigate to localhost:8000 in your browser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.core - ERROR - Exception while handling op broadcast\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/core.py\", line 319, in connect\n",
      "    handshake = await asyncio.wait_for(comm.read(), time_left())\n",
      "  File \"/home1/radrogue/.conda/envs/environmentname/lib/python3.7/asyncio/tasks.py\", line 449, in wait_for\n",
      "    raise futures.TimeoutError()\n",
      "concurrent.futures._base.TimeoutError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 521, in handle_comm\n",
      "    result = await result\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/scheduler.py\", line 6021, in broadcast\n",
      "    [send_message(address) for address in addresses if address is not None]\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 208, in All\n",
      "    result = await tasks.next()\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/scheduler.py\", line 6012, in send_message\n",
      "    comm = await self.rpc.connect(addr)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 1071, in connect\n",
      "    raise exc\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 1055, in connect\n",
      "    comm = await fut\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/core.py\", line 326, in connect\n",
      "    ) from exc\n",
      "OSError: Timed out during handshake while connecting to tcp://192.168.86.140:41952 after 30 s\n",
      "Exception in thread WorkerMemory:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/core.py\", line 319, in connect\n",
      "    handshake = await asyncio.wait_for(comm.read(), time_left())\n",
      "  File \"/home1/radrogue/.conda/envs/environmentname/lib/python3.7/asyncio/tasks.py\", line 449, in wait_for\n",
      "    raise futures.TimeoutError()\n",
      "concurrent.futures._base.TimeoutError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.conda/envs/environmentname/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home1/radrogue/.conda/envs/environmentname/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home1/radrogue/.conda/envs/environmentname/lib/python3.7/site-packages/dask_memusage.py\", line 66, in _fetch_memory\n",
      "    worker_to_mem = client.run(_process_memory)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/client.py\", line 2472, in run\n",
      "    return self.sync(self._run, function, *args, **kwargs)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 311, in sync\n",
      "    self.loop, func, *args, callback_timeout=callback_timeout, **kwargs\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 364, in sync\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 349, in f\n",
      "    result[0] = yield future\n",
      "  File \"/usr/global/Anaconda/2019-10/lib/python3.7/site-packages/tornado/gen.py\", line 735, in run\n",
      "    value = future.result()\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/client.py\", line 2401, in _run\n",
      "    nanny=nanny,\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 886, in send_recv_from_rpc\n",
      "    result = await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 679, in send_recv\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 521, in handle_comm\n",
      "    result = await result\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/scheduler.py\", line 6021, in broadcast\n",
      "    [send_message(address) for address in addresses if address is not None]\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 208, in All\n",
      "    result = await tasks.next()\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/scheduler.py\", line 6012, in send_message\n",
      "    comm = await self.rpc.connect(addr)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 1071, in connect\n",
      "    raise exc\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 1055, in connect\n",
      "    comm = await fut\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/core.py\", line 326, in connect\n",
      "    ) from exc\n",
      "OSError: Timed out during handshake while connecting to tcp://192.168.86.140:41952 after 30 s\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client shutdown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/radrogue/.local/lib/python3.7/site-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "if refilter:\n",
    "    importlib.reload(eeg_check)\n",
    "    try: \n",
    "        client.shutdown()\n",
    "        print('client shutdown')\n",
    "    except: \n",
    "        print('no client')\n",
    "\n",
    "    # creates cluster jobs, 1 for each subject, each with 10 GB limit of\n",
    "    # memory to calculate powers for subject and region\n",
    "    # client.map(function, p1, p2, p3)\n",
    "\n",
    "    client = CMLDask.new_dask_client(\"filter_pairs\", \"40GB\")\n",
    "    futures = client.map(get_filtered_pairs, subjects, sessions)\n",
    "    # waits until the cluster job is complete\n",
    "    wait(futures)\n",
    "    f_pairs = client.gather(CMLDask.filter_futures(futures))\n",
    "    exceptions = CMLDask.get_exceptions(futures, subjects).param\n",
    "    # *** Checks for patients with bad eeg and removes them from analysis *** #\n",
    "    bad_sub_is = []\n",
    "    for bad_sub in exceptions:\n",
    "        bad_sub_i = np.where(np.array(subjects) == bad_sub)[0][0]\n",
    "        bad_sub_is.append(bad_sub_i)\n",
    "        loc.pop(bad_sub_i)\n",
    "        subjects.remove(bad_sub)\n",
    "    if exceptions.empty:\n",
    "        print('No exceptions')\n",
    "    try: \n",
    "        client.shutdown()\n",
    "        print('client shutdown')\n",
    "    except: \n",
    "        print('no client')\n",
    "\n",
    "    filt_pairs = []\n",
    "    for df in f_pairs:\n",
    "        good = df[df.bad == 0]\n",
    "        filt_pairs.append(good)\n",
    "    np.save('bad_subs', [bad_sub_is])\n",
    "    np.save('filtered_pairs', filt_pairs)\n",
    "else:\n",
    "    filt_pairs = np.load('filtered_pairs.npy', allow_pickle=True)\n",
    "    bad_sub_is = np.load('bad_subs.npy')\n",
    "    loc = [i for j, i in enumerate(loc) if j not in bad_sub_is]\n",
    "    subjects = [i for j, i in enumerate(subjects) if j not in bad_sub_is]\n",
    "    print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a61eb5e-8077-4fef-9a2c-416ccebe350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Split electrodes into ROIs *** #\n",
    "reload(regionalizationModule)\n",
    "hippo_subs=[];mtl_subs=[];fg_subs=[];ltc_subs=[];\n",
    "hippo_pairs=[];mtl_pairs=[];fg_pairs=[];ltc_pairs=[];\n",
    "for index, sub in enumerate(subjects):\n",
    "    elec_regions,atlas_type,pair_number,has_stein_das = regionalizationModule.get_elec_regions(loc[index],filt_pairs[index])\n",
    "\n",
    "    hippo = filt_pairs[index].iloc[pair_number[np.where(np.isin(elec_regions,HPC_labels))[0]]]\n",
    "    mtl = filt_pairs[index].iloc[pair_number[np.where(np.isin(elec_regions,nonHPC_MTL_labels))[0]]]\n",
    "    fg = filt_pairs[index].iloc[pair_number[np.where(np.isin(elec_regions,FG_labels))[0]]]\n",
    "    ltc = filt_pairs[index].iloc[pair_number[np.where(np.isin(elec_regions,LTC_labels))[0]]]\n",
    "\n",
    "    # *** Append selected pairs to separated lists for later analysis *** #\n",
    "    if not hippo.empty:\n",
    "        hippo_subs.append(sub)\n",
    "        hippo_pairs.append(hippo)\n",
    "    if not mtl.empty:\n",
    "        mtl_subs.append(sub)\n",
    "        mtl_pairs.append(mtl)\n",
    "    if not fg.empty:\n",
    "        fg_subs.append(sub)\n",
    "        fg_pairs.append(fg)\n",
    "    if not ltc.empty:\n",
    "        ltc_subs.append(sub)\n",
    "        ltc_pairs.append(ltc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cca9fce-8fea-432a-a7ae-344bf075e327",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set your hemisphere and region here\n",
    "# All regions at once\n",
    "def do_stats_and_stuff(subs, pairs, hemisphere, region, rerun_powers = False):\n",
    "    print(hemisphere,region)\n",
    "    try: client.shutdown()\n",
    "    except: print('no client')\n",
    "    print(len(subs), 'with electrodes in {} {}'.format(hemisphere, region))\n",
    "    hemispheres = []\n",
    "    regions = []\n",
    "    for i in subs:\n",
    "        regions.append(region)\n",
    "        hemispheres.append(hemisphere)\n",
    "    if rerun_powers:\n",
    "        try: client.shutdown()\n",
    "        except: print('no client')\n",
    "\n",
    "        # creates cluster jobs, 1 for each subject, each with 10 GB limit of\n",
    "        # memory to calculate powers for subject and region\n",
    "        # client.map(function, p1, p2, p3)\n",
    "\n",
    "        client = CMLDask.new_dask_client(\"iEEG_powers\", \"10GB\")\n",
    "        futures = client.map(repeat_sme.get_enc_powers, subs, pairs, hemispheres, regions)\n",
    "        # waits until the cluster job is complete\n",
    "        wait(futures)\n",
    "        power_exc = CMLDask.get_exceptions(futures, subs)\n",
    "        pow_results = client.gather(CMLDask.filter_futures(futures))\n",
    "        \n",
    "    # gathers any errors\n",
    "    # shuts down the cluster\n",
    "\n",
    "    try: client.shutdown()\n",
    "    except: print('no client')\n",
    "    # displays errors\n",
    "\n",
    "    # creates new cluster jobs, 1 for each subject, 50GB memory to calculate t-stats\n",
    "    client = CMLDask.new_dask_client(\"iEEG_stats\", \"60GB\")\n",
    "    futures = client.map(repeat_sme.enc_power_statistics, subs, pairs, hemispheres, regions)\n",
    "    \n",
    "    # gathers report on how this function ran\n",
    "    # good means it was completed, otherwise shows error message\n",
    "    wait(futures)\n",
    "    exceptions = CMLDask.get_exceptions(futures, subs)\n",
    "    results = client.gather(CMLDask.filter_futures(futures))\n",
    "    client.shutdown()\n",
    "    if rerun_powers:\n",
    "        return power_exc, pow_results, results, exceptions\n",
    "    return results, exceptions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bbce0b44-4190-4996-97da-c8fecbbcb240",
   "metadata": {},
   "source": [
    "reload(repeat_sme)\n",
    "repeat_sme.enc_power_statistics(hippo_subs[0], hippo_pairs[0], '', 'hippo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c53ca82-1bac-4325-90dc-e2a3725d1846",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading modules\n",
      " hippo\n",
      "no client\n",
      "24 with electrodes in  hippo\n",
      "no client\n",
      "Unique port for radrogue is 51417\n",
      "{'dashboard_address': ':51417'}\n",
      "To view the dashboard, run: \n",
      "`ssh -fN radrogue@rhino2.psych.upenn.edu -L 8000:192.168.86.146:51417` in your local computer's terminal (NOT rhino) \n",
      "and then navigate to localhost:8000 in your browser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils - ERROR - 'str' object has no attribute 'text'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 681, in log_errors\n",
      "    yield\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/dashboard/components/scheduler.py\", line 344, in update\n",
      "    self.root.title.text = title\n",
      "AttributeError: 'str' object has no attribute 'text'\n",
      "distributed.utils - ERROR - 'str' object has no attribute 'text'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 681, in log_errors\n",
      "    yield\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/dashboard/components/scheduler.py\", line 3134, in status_doc\n",
      "    cluster_memory.update()\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/bokeh/core/property/validation.py\", line 95, in func\n",
      "    return input_function(*args, **kwargs)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/dashboard/components/scheduler.py\", line 344, in update\n",
      "    self.root.title.text = title\n",
      "AttributeError: 'str' object has no attribute 'text'\n",
      "tornado.application - ERROR - Uncaught exception GET /status (192.168.86.150)\n",
      "HTTPServerRequest(protocol='http', host='localhost:8000', method='GET', uri='/status', version='HTTP/1.1', remote_ip='192.168.86.150')\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/global/Anaconda/2019-10/lib/python3.7/site-packages/tornado/web.py\", line 1699, in _execute\n",
      "    result = await result\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/bokeh/server/views/doc_handler.py\", line 54, in get\n",
      "    session = await self.get_session()\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/bokeh/server/views/session_handler.py\", line 144, in get_session\n",
      "    session = await self.application_context.create_session_if_needed(session_id, self.request, token)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/bokeh/server/contexts.py\", line 243, in create_session_if_needed\n",
      "    self._application.initialize_document(doc)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/bokeh/application/application.py\", line 194, in initialize_document\n",
      "    h.modify_document(doc)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/bokeh/application/handlers/function.py\", line 143, in modify_document\n",
      "    self._func(doc)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/dashboard/components/scheduler.py\", line 3134, in status_doc\n",
      "    cluster_memory.update()\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/bokeh/core/property/validation.py\", line 95, in func\n",
      "    return input_function(*args, **kwargs)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/dashboard/components/scheduler.py\", line 344, in update\n",
      "    self.root.title.text = title\n",
      "AttributeError: 'str' object has no attribute 'text'\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <TCP (closed) Scheduler Broadcast local=tcp://192.168.86.146:47342 remote=tcp://192.168.86.117:39242>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 205, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/global/Anaconda/2019-10/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.throw(*exc_info)  # type: ignore\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 221, in quiet\n",
      "    yield task\n",
      "  File \"/usr/global/Anaconda/2019-10/lib/python3.7/site-packages/tornado/gen.py\", line 735, in run\n",
      "    value = future.result()\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/scheduler.py\", line 6015, in send_message\n",
      "    resp = await send_recv(comm, close=True, serializers=serializers, **msg)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 663, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 221, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 128, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler Broadcast local=tcp://192.168.86.146:47342 remote=tcp://192.168.86.117:39242>: Stream is closed\n",
      "Exception in thread WorkerMemory:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 205, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.conda/envs/environmentname/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home1/radrogue/.conda/envs/environmentname/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home1/radrogue/.conda/envs/environmentname/lib/python3.7/site-packages/dask_memusage.py\", line 66, in _fetch_memory\n",
      "    worker_to_mem = client.run(_process_memory)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/client.py\", line 2472, in run\n",
      "    return self.sync(self._run, function, *args, **kwargs)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 311, in sync\n",
      "    self.loop, func, *args, callback_timeout=callback_timeout, **kwargs\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 364, in sync\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 349, in f\n",
      "    result[0] = yield future\n",
      "  File \"/usr/global/Anaconda/2019-10/lib/python3.7/site-packages/tornado/gen.py\", line 735, in run\n",
      "    value = future.result()\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/client.py\", line 2401, in _run\n",
      "    nanny=nanny,\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 886, in send_recv_from_rpc\n",
      "    result = await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 663, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 221, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 128, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.broadcast local=tcp://192.168.86.146:49808 remote=tcp://192.168.86.146:46194>: Stream is closed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "reload(repeat_sme)\n",
    "hippo = do_stats_and_stuff(hippo_subs, hippo_pairs, '', 'hippo', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf81fc1-49db-4e9b-a0aa-93291afceaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hippo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65954174-6816-4cc2-8744-0a10486ba473",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mtl\n",
      "no client\n",
      "25 with electrodes in  mtl\n",
      "no client\n",
      "Unique port for radrogue is 51417\n",
      "{'dashboard_address': ':51417'}\n",
      "To view the dashboard, run: \n",
      "`ssh -fN radrogue@rhino2.psych.upenn.edu -L 8000:192.168.86.146:51417` in your local computer's terminal (NOT rhino) \n",
      "and then navigate to localhost:8000 in your browser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "concurrent.futures._base.CancelledError\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "concurrent.futures._base.CancelledError\n",
      "Task exception was never retrieved\n",
      "future: <Task finished coro=<Scheduler.broadcast.<locals>.send_message() done, defined at /home1/radrogue/.local/lib/python3.7/site-packages/distributed/scheduler.py:6011> exception=CommClosedError('in <TCP (closed) Scheduler Broadcast local=tcp://192.168.86.146:57760 remote=tcp://192.168.86.119:41356>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 205, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/scheduler.py\", line 6015, in send_message\n",
      "    resp = await send_recv(comm, close=True, serializers=serializers, **msg)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 663, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 221, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 128, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler Broadcast local=tcp://192.168.86.146:57760 remote=tcp://192.168.86.119:41356>: Stream is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished coro=<Scheduler.broadcast.<locals>.send_message() done, defined at /home1/radrogue/.local/lib/python3.7/site-packages/distributed/scheduler.py:6011> exception=CommClosedError('in <TCP (closed) Scheduler Broadcast local=tcp://192.168.86.146:43940 remote=tcp://192.168.86.135:41839>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 205, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/scheduler.py\", line 6015, in send_message\n",
      "    resp = await send_recv(comm, close=True, serializers=serializers, **msg)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 663, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 221, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 128, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler Broadcast local=tcp://192.168.86.146:43940 remote=tcp://192.168.86.135:41839>: Stream is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished coro=<Scheduler.broadcast.<locals>.send_message() done, defined at /home1/radrogue/.local/lib/python3.7/site-packages/distributed/scheduler.py:6011> exception=CommClosedError('in <TCP (closed) Scheduler Broadcast local=tcp://192.168.86.146:51446 remote=tcp://192.168.86.135:42694>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 205, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/scheduler.py\", line 6015, in send_message\n",
      "    resp = await send_recv(comm, close=True, serializers=serializers, **msg)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 663, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 221, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 128, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler Broadcast local=tcp://192.168.86.146:51446 remote=tcp://192.168.86.135:42694>: Stream is closed\n",
      "Exception in thread WorkerMemory:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 205, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.conda/envs/environmentname/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home1/radrogue/.conda/envs/environmentname/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home1/radrogue/.conda/envs/environmentname/lib/python3.7/site-packages/dask_memusage.py\", line 66, in _fetch_memory\n",
      "    worker_to_mem = client.run(_process_memory)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/client.py\", line 2472, in run\n",
      "    return self.sync(self._run, function, *args, **kwargs)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 311, in sync\n",
      "    self.loop, func, *args, callback_timeout=callback_timeout, **kwargs\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 364, in sync\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 349, in f\n",
      "    result[0] = yield future\n",
      "  File \"/usr/global/Anaconda/2019-10/lib/python3.7/site-packages/tornado/gen.py\", line 735, in run\n",
      "    value = future.result()\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/client.py\", line 2401, in _run\n",
      "    nanny=nanny,\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 886, in send_recv_from_rpc\n",
      "    result = await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 663, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 221, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 128, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.broadcast local=tcp://192.168.86.146:49332 remote=tcp://192.168.86.146:39476>: Stream is closed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "mtl = do_stats_and_stuff(mtl_subs, mtl_pairs, '', 'mtl', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c118326f-2312-4f7f-ae98-a605be7c772d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['R1204T worked!',\n",
       "  'R1501J worked!',\n",
       "  ['Pres1 SME'],\n",
       "  ['Pres1 SME'],\n",
       "  'R1528E worked!',\n",
       "  'R1531T worked!',\n",
       "  'R1534D worked!',\n",
       "  'R1547D worked!',\n",
       "  'R1564J worked!',\n",
       "  'R1568E worked!',\n",
       "  'R1579T worked!',\n",
       "  'R1582E worked!',\n",
       "  'R1584J worked!',\n",
       "  ['Pres1 SME'],\n",
       "  'R1589T worked!',\n",
       "  'R1590T worked!',\n",
       "  'R1593D worked!',\n",
       "  'R1594E worked!',\n",
       "  'R1604J worked!',\n",
       "  'R1610D worked!',\n",
       "  'R1611T worked!',\n",
       "  'R1613T worked!',\n",
       "  ['Pres1 SME'],\n",
       "  'R1618J worked!'],\n",
       "         param                                          exception  \\\n",
       " index                                                              \n",
       " 9      R1566D  ValueError('all the input array dimensions for...   \n",
       " \n",
       "                               traceback_obj  \n",
       " index                                        \n",
       " 9      <traceback object at 0x2b5d87a845f0>  )"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba17a244-77b8-4300-910e-d1106f030498",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fg\n",
      "no client\n",
      "22 with electrodes in  fg\n",
      "no client\n",
      "Unique port for radrogue is 51417\n",
      "{'dashboard_address': ':51417'}\n",
      "To view the dashboard, run: \n",
      "`ssh -fN radrogue@rhino2.psych.upenn.edu -L 8000:192.168.86.146:40833` in your local computer's terminal (NOT rhino) \n",
      "and then navigate to localhost:8000 in your browser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/radrogue/.local/lib/python3.7/site-packages/distributed/node.py:161: UserWarning: Port 51417 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 40833 instead\n",
      "  f\"Port {expected} is already in use.\\n\"\n",
      "Exception in thread WorkerMemory:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 205, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.conda/envs/environmentname/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home1/radrogue/.conda/envs/environmentname/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home1/radrogue/.conda/envs/environmentname/lib/python3.7/site-packages/dask_memusage.py\", line 66, in _fetch_memory\n",
      "    worker_to_mem = client.run(_process_memory)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/client.py\", line 2472, in run\n",
      "    return self.sync(self._run, function, *args, **kwargs)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 311, in sync\n",
      "    self.loop, func, *args, callback_timeout=callback_timeout, **kwargs\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 364, in sync\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 349, in f\n",
      "    result[0] = yield future\n",
      "  File \"/usr/global/Anaconda/2019-10/lib/python3.7/site-packages/tornado/gen.py\", line 735, in run\n",
      "    value = future.result()\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/client.py\", line 2401, in _run\n",
      "    nanny=nanny,\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 886, in send_recv_from_rpc\n",
      "    result = await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 663, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 221, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 128, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.broadcast local=tcp://192.168.86.146:40318 remote=tcp://192.168.86.146:33270>: Stream is closed\n",
      "\n",
      "Exception in thread WorkerMemory:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 205, in read\n",
      "    frames_nbytes = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/radrogue/.conda/envs/environmentname/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home1/radrogue/.conda/envs/environmentname/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home1/radrogue/.conda/envs/environmentname/lib/python3.7/site-packages/dask_memusage.py\", line 66, in _fetch_memory\n",
      "    worker_to_mem = client.run(_process_memory)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/client.py\", line 2472, in run\n",
      "    return self.sync(self._run, function, *args, **kwargs)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 311, in sync\n",
      "    self.loop, func, *args, callback_timeout=callback_timeout, **kwargs\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 364, in sync\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/utils.py\", line 349, in f\n",
      "    result[0] = yield future\n",
      "  File \"/usr/global/Anaconda/2019-10/lib/python3.7/site-packages/tornado/gen.py\", line 735, in run\n",
      "    value = future.result()\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/client.py\", line 2401, in _run\n",
      "    nanny=nanny,\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 886, in send_recv_from_rpc\n",
      "    result = await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/core.py\", line 663, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 221, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home1/radrogue/.local/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 128, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.broadcast local=tcp://192.168.86.146:51438 remote=tcp://192.168.86.146:46879>: Stream is closed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "fg = do_stats_and_stuff(fg_subs, fg_pairs, '', 'fg', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b229b6fe-7ad6-446f-93fe-fd30108aa8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['R1204T worked!',\n",
       "  ['Pres1 SME'],\n",
       "  'R1528E worked!',\n",
       "  'R1531T worked!',\n",
       "  'R1534D worked!',\n",
       "  'R1547D worked!',\n",
       "  'R1556J worked!',\n",
       "  'R1564J worked!',\n",
       "  'R1568E worked!',\n",
       "  'R1579T worked!',\n",
       "  'R1582E worked!',\n",
       "  'R1584J worked!',\n",
       "  ['Pres1 SME'],\n",
       "  'R1589T worked!',\n",
       "  'R1593D worked!',\n",
       "  'R1594E worked!',\n",
       "  ['Pres1 SME'],\n",
       "  'R1610D worked!',\n",
       "  'R1613T worked!',\n",
       "  ['Pres1 SME'],\n",
       "  'R1618J worked!'],\n",
       "         param                                          exception  \\\n",
       " index                                                              \n",
       " 8      R1566D  ValueError('all the input array dimensions for...   \n",
       " \n",
       "                               traceback_obj  \n",
       " index                                        \n",
       " 8      <traceback object at 0x2b5da49d6280>  )"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9851197d-12bc-47a8-8614-8376a37d6299",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "ltc = do_stats_and_stuff(ltc_subs, ltc_pairs, '', 'ltc', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "887e4f3f-451a-4026-a245-3cf3d0711719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['R1204T worked!',\n",
       "  'R1501J worked!',\n",
       "  ['Pres1 SME'],\n",
       "  ['Pres1 SME'],\n",
       "  'R1528E worked!',\n",
       "  'R1531T worked!',\n",
       "  ['Pres1 SME'],\n",
       "  ['Pres1 SME'],\n",
       "  'R1556J worked!',\n",
       "  'R1564J worked!',\n",
       "  ['Pres1 SME'],\n",
       "  'R1579T worked!',\n",
       "  ['2R-1R'],\n",
       "  ['Pres1 SME'],\n",
       "  ['Pres1 SME'],\n",
       "  ['Pres1 SME'],\n",
       "  'R1590T worked!',\n",
       "  'R1593D worked!',\n",
       "  'R1594E worked!',\n",
       "  'R1604J worked!',\n",
       "  ['2-1', '2N-1N'],\n",
       "  'R1613T worked!',\n",
       "  ['Pres1 SME'],\n",
       "  ['Pres1 SME']],\n",
       "         param                                          exception  \\\n",
       " index                                                              \n",
       " 10     R1566D  ValueError('all the input array dimensions for...   \n",
       " 22     R1611T  MemoryError((19, 24, 240, 799), dtype('float64'))   \n",
       " \n",
       "                               traceback_obj  \n",
       " index                                        \n",
       " 10     <traceback object at 0x2b5e0c720280>  \n",
       " 22     <traceback object at 0x2b5e0cd287d0>  )"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "concurrent.futures._base.CancelledError\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "concurrent.futures._base.CancelledError\n"
     ]
    }
   ],
   "source": [
    "ltc"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b541b4c1-f390-4d7b-a7e4-ca69463a84d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# describes regions of interest\n",
    "regions = ['parietal', 'Hippocampus', 'entorhinal', 'Amygdala','parietal', \n",
    "           'parahippocampal', 'frontal gyrus', 'inferior frontal gyrus', 'middle frontal gyrus',\n",
    "          'superior frontal gyrus', 'temporal gyrus', 'MTG', \n",
    "           'inferior temporal gyrus', 'superior temporal gyrus', 'MTL']\n",
    "hemispheres = ['Right', 'Left', '']\n",
    "# stores subjects by ROI in a dataframe\n",
    "results = pd.DataFrame(columns=['region', 'num_subs', 'subjects'])\n",
    "for h in hemispheres:\n",
    "    for r in regions:\n",
    "        \n",
    "        subs = all_loc_p[(all_loc_p['atlases.whole_brain'].str.contains(r)) & all_loc_p['atlases.whole_brain'].\n",
    "                     str.contains(h)].subject.unique()\n",
    "        n = all_loc_p[(all_loc_p['atlases.whole_brain'].str.contains(r)) & all_loc_p['atlases.whole_brain'].\n",
    "                     str.contains(h)].subject.nunique()\n",
    "        if h == '':\n",
    "            results = results.append(pd.DataFrame(dict(region = r, num_subs = n, subjects = [subs]), index = [len(results)]))\n",
    "        else:\n",
    "            results = results.append(pd.DataFrame(dict(region = h +' ' + r, num_subs = n, subjects = [subs]), index = [len(results)]))\n",
    "# LTL = results[(results.hemisphere == 'Left') & (results.region == 'temporal')]\n",
    "\n",
    "display(results.set_index('region'))\n",
    "\n",
    "\n",
    "path = '/scratch/radrogue/RepFR1/'\n",
    "print('processed regions:')\n",
    "for file in os.listdir(path):\n",
    "    d = os.path.join(path, file)\n",
    "    if os.path.isdir(d):\n",
    "        words = d.split('/')[-1].split('_')\n",
    "        print(words[0] + ' ' + words[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4b2b1d-d13c-44f8-8890-842f59ccd777",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## All at Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96af8c17-db33-4147-a343-68441edbd12e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set your hemisphere and region here\n",
    "# All regions at once\n",
    "\n",
    "def do_stats_and_stuff(subs, pairs, hemisphere, region):\n",
    "    print(hemisphere,region)\n",
    "    print(len(subs), 'with electrodes in {} {}'.format(hemisphere, region))\n",
    "    hemispheres = []\n",
    "    regions = []\n",
    "    for i in subs:\n",
    "        regions.append(region)\n",
    "        hemispheres.append(hemisphere)\n",
    "\n",
    "    try: client.shutdown()\n",
    "    except: print('no client')\n",
    "\n",
    "    # creates cluster jobs, 1 for each subject, each with 10 GB limit of\n",
    "    # memory to calculate powers for subject and region\n",
    "    # client.map(function, p1, p2, p3)\n",
    "\n",
    "    client = CMLDask.new_dask_client(\"iEEG_powers\", \"10GB\")\n",
    "    futures = client.map(get_enc_powers, subs, pairs, hemispheres, regions)\n",
    "    # waits until the cluster job is complete\n",
    "    wait(futures)\n",
    "    # gathers any errors\n",
    "    # shuts down the cluster\n",
    "\n",
    "    try: client.shutdown()\n",
    "    except: print('no client')\n",
    "    # displays errors\n",
    "\n",
    "    # creates new cluster jobs, 1 for each subject, 50GB memory to calculate t-stats\n",
    "    client = CMLDask.new_dask_client(\"iEEG_stats\", \"50GB\")\n",
    "    futures = client.map(enc_power_statistics, subs, pairs, hemispheres, regions)\n",
    "\n",
    "    # gathers report on how this function ran\n",
    "    # good means it was completed, otherwise shows error message\n",
    "    wait(futures)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da943f97-9e8b-403e-9eac-0510317d8fcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# set your hemisphere and region here\n",
    "# All regions at once\n",
    "major_hemispheres = ['Left', 'Right']\n",
    "major_regions = ['MTL', 'Hippocampus', 'MTG', 'frontal gyrus']\n",
    "\n",
    "for region in major_regions:\n",
    "    for hemisphere in major_hemispheres:\n",
    "        print(hemisphere,region)\n",
    "        # selects the subjects with electrodes in your selected region\n",
    "        # MTL is multiple regions, so specifically have to look through this way\n",
    "        if region == 'MTL':\n",
    "            subs = results[results.region == hemisphere+' '+'parahippocampal'].subjects.iloc[0]\n",
    "            subs = np.concatenate([subs, results[results.region == hemisphere+' '+'Amygdala'].subjects.iloc[0]])\n",
    "            subs = np.concatenate([subs, results[results.region == hemisphere+' '+'entorhinal'].subjects.iloc[0]])\n",
    "            subs = np.unique(subs)\n",
    "        else:\n",
    "            subs = subs = results[results.region == hemisphere+' '+region].subjects.iloc[0]\n",
    "        print(len(subs), 'with electrodes in localization')\n",
    "\n",
    "\n",
    "        # checks that the pairs in that region were actually recorded from\n",
    "        # We only record 128 channels for most of this data\n",
    "        # Localization includes all electrodes (up to 256)\n",
    "        # So this checks that the electrodes are also in pairs, which only shows pairs where\n",
    "        # data was recorded\n",
    "        pairs = []\n",
    "        for sub in subs:\n",
    "            data = get_data_index('r1'); data = data[(data.experiment == 'RepFR1') & (data.subject==sub)]\n",
    "            r = CMLReader(subject=sub, experiment='RepFR1', session = data.session.iloc[0])\n",
    "            loc = r.load(\"localization\")\n",
    "            t_pairs = r.load('pairs')\n",
    "            loc_p = loc.loc['pairs']\n",
    "            if region == 'MTL':\n",
    "                f_loc_p = loc_p[(loc_p['atlases.whole_brain'].str.contains(hemisphere)) & \n",
    "                                ((loc_p['atlases.whole_brain'].str.contains('parahippocampal')) | (loc_p['atlases.whole_brain'].str.contains('Amygdala')) \n",
    "                                 | (loc_p['atlases.whole_brain'].str.contains('entorhinal')))]\n",
    "            else:\n",
    "                f_loc_p = loc_p[(loc_p['atlases.whole_brain'].str.contains(hemisphere)) & loc_p['atlases.whole_brain'].str.contains(region)]\n",
    "            pairs_filter = []\n",
    "            for labels in f_loc_p.index:\n",
    "                biploar_label = labels[0]+'-'+labels[1]\n",
    "                pairs_filter.append(biploar_label)\n",
    "            t_pairs = t_pairs[t_pairs.label.isin(pairs_filter)]\n",
    "            if t_pairs.empty:\n",
    "                subs = subs[subs != sub]\n",
    "            else:\n",
    "                pairs.append(t_pairs)\n",
    "        print(len(subs), 'with region in localization & pairs')\n",
    "        # print(subs)\n",
    "        # makes lists of hemi and reg as same length as subs array\n",
    "        # this is because Dask requires all of your parameters to have the same shape\n",
    "        hemispheres = []\n",
    "        regions = []\n",
    "        print(subs)\n",
    "        for i in subs:\n",
    "            regions.append(region)\n",
    "            hemispheres.append(hemisphere)\n",
    "\n",
    "\n",
    "        # import Dask and Dask functions to run script on the cluster\n",
    "        import CMLDask\n",
    "        from dask.distributed import wait, as_completed, progress\n",
    "        from dask import config\n",
    "        config.set({'timeouts':{'connect':'90s', 'tcp':'120s'}})\n",
    "        try: client.shutdown()\n",
    "        except: print('no client')\n",
    "\n",
    "        # creates cluster jobs, 1 for each subject, each with 10 GB limit of\n",
    "        # memory to calculate powers for subject and region\n",
    "        # client.map(function, p1, p2, p3)\n",
    "\n",
    "        client = CMLDask.new_dask_client(\"iEEG_powers\", \"10GB\")\n",
    "        futures = client.map(get_enc_powers, subs, pairs, hemispheres, regions)\n",
    "        # waits until the cluster job is complete\n",
    "        wait(futures)\n",
    "        # gathers any errors\n",
    "        # shuts down the cluster\n",
    "\n",
    "        client.shutdown()\n",
    "        # displays errors\n",
    "\n",
    "        # creates new cluster jobs, 1 for each subject, 50GB memory to calculate t-stats\n",
    "        client = CMLDask.new_dask_client(\"iEEG_stats\", \"50GB\")\n",
    "        futures = client.map(enc_power_statistics, subs, pairs, hemispheres, regions)\n",
    "\n",
    "        # gathers report on how this function ran\n",
    "        # good means it was completed, otherwise shows error message\n",
    "        wait(futures)\n",
    "\n",
    "        # shuts down client\n",
    "        client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c083a36-cf2b-4369-b50d-2fe195b81933",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## One at a Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2094fa67-2d06-45db-b95e-a0e7de59977c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set your hemisphere and region here\n",
    "hemisphere = 'Right'\n",
    "region = 'MTL'\n",
    "\n",
    "# selects the subjects with electrodes in your selected region\n",
    "# MTL is multiple regions, so specifically have to look through this way\n",
    "if region == 'MTL':\n",
    "    subs = results[results.region == hemisphere+' '+'parahippocampal'].subjects.iloc[0]\n",
    "    subs = np.concatenate([subs, results[results.region == hemisphere+' '+'Amygdala'].subjects.iloc[0]])\n",
    "    subs = np.concatenate([subs, results[results.region == hemisphere+' '+'entorhinal'].subjects.iloc[0]])\n",
    "    subs = np.unique(subs)\n",
    "else:\n",
    "    subs = subs = results[results.region == hemisphere+' '+region].subjects.iloc[0]\n",
    "print(len(subs), 'with electrodes in localization')\n",
    "\n",
    "\n",
    "# checks that the pairs in that region were actually recorded from\n",
    "# We only record 128 channels for most of this data\n",
    "# Localization includes all electrodes (up to 256)\n",
    "# So this checks that the electrodes are also in pairs, which only shows pairs where\n",
    "# data was recorded\n",
    "pairs = []\n",
    "for sub in subs:\n",
    "    data = get_data_index('r1'); data = data[(data.experiment == 'RepFR1') & (data.subject==sub)]\n",
    "    r = CMLReader(subject=sub, experiment='RepFR1', session = data.session.iloc[0])\n",
    "    loc = r.load(\"localization\")\n",
    "    t_pairs = r.load('pairs')\n",
    "    loc_p = loc.loc['pairs']\n",
    "    if region == 'MTL':\n",
    "        f_loc_p = loc_p[(loc_p['atlases.whole_brain'].str.contains(hemisphere)) & \n",
    "                        ((loc_p['atlases.whole_brain'].str.contains('parahippocampal')) | (loc_p['atlases.whole_brain'].str.contains('Amygdala')) \n",
    "                         | (loc_p['atlases.whole_brain'].str.contains('entorhinal')))]\n",
    "    else:\n",
    "        f_loc_p = loc_p[(loc_p['atlases.whole_brain'].str.contains(hemisphere)) & loc_p['atlases.whole_brain'].str.contains(region)]\n",
    "    pairs_filter = []\n",
    "    for labels in f_loc_p.index:\n",
    "        biploar_label = labels[0]+'-'+labels[1]\n",
    "        pairs_filter.append(biploar_label)\n",
    "    t_pairs = t_pairs[t_pairs.label.isin(pairs_filter)]\n",
    "    if t_pairs.empty:\n",
    "        subs = subs[subs != sub]\n",
    "    else:\n",
    "        pairs.append(t_pairs)\n",
    "print(len(subs), 'with region in localization & pairs')\n",
    "# print(subs)\n",
    "# makes lists of hemi and reg as same length as subs array\n",
    "# this is because Dask requires all of your parameters to have the same shape\n",
    "hemispheres = []\n",
    "regions = []\n",
    "print(subs)\n",
    "for i in subs:\n",
    "    regions.append(region)\n",
    "    hemispheres.append(hemisphere)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e371d97-7ef5-4b2b-b452-2a42d17b559f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe8b363-baf1-41ab-8d6b-7820312deec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import Dask and Dask functions to run script on the cluster\n",
    "import CMLDask\n",
    "from dask.distributed import wait, as_completed, progress\n",
    "from dask import config\n",
    "config.set({'timeouts':{'connect':'90s', 'tcp':'120s'}})\n",
    "try: client.shutdown()\n",
    "except: print('no client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed007059-95b9-44cd-8069-36d5e0595f31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creates cluster jobs, 1 for each subject, each with 10 GB limit of\n",
    "# memory to calculate powers for subject and region\n",
    "# client.map(function, p1, p2, p3)\n",
    "\n",
    "client = CMLDask.new_dask_client(\"iEEG_powers\", \"10GB\")\n",
    "futures = client.map(get_enc_powers, subs, pairs, hemispheres, regions)\n",
    "progress(futures)\n",
    "# waits until the cluster job is complete\n",
    "wait(futures)\n",
    "# gathers any errors\n",
    "power_errors = client.gather(futures)\n",
    "# shuts down the cluster\n",
    "\n",
    "client.shutdown()\n",
    "# displays errors\n",
    "power_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede600f4-6297-4e22-beb4-bf3f8c02d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates new cluster jobs, 1 for each subject, 50GB memory to calculate t-stats\n",
    "client = CMLDask.new_dask_client(\"iEEG_stats\", \"50GB\")\n",
    "futures = client.map(enc_power_statistics, subs, pairs, hemispheres, regions)\n",
    "progress(futures)\n",
    "\n",
    "# gathers report on how this function ran\n",
    "# good means it was completed, otherwise shows error message\n",
    "wait(futures)\n",
    "ahh = client.gather(futures)\n",
    "\n",
    "# shuts down client\n",
    "client.shutdown()\n",
    "ahh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c94a2b-a087-4cfa-9023-34b01b96c786",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMLDask.get_exceptions(futures, subs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "081a7a70-f48a-493d-a6b5-88e076b89855",
   "metadata": {},
   "source": [
    "# set your hemisphere and region here\n",
    "regions = ['Left frontal', 'Left Hippocampus',\n",
    "            'Left MTG', 'Left parahippocampal', 'Left entorhinal',  'Left Amygdala', \n",
    "             'Left_orbital', 'Right_frontal', 'Right_Hippocampus', \n",
    "             'Right_parahippocampal', 'Right_MTG', 'Right_entorhinal', \n",
    "             'Right_Amygdala', 'Right_orbital', 'Left_temporal', 'Right_temporal']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8067c439-58bf-4ffc-a651-5e97617d1256",
   "metadata": {},
   "source": [
    "regions = results[~(results.region.str.contains('Left')) & ~(results.region.str.contains('Right'))].region.unique()\n",
    "regions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "419e65bf-ac6b-44ff-8adf-09689e536faf",
   "metadata": {},
   "source": [
    "for r in regions:\n",
    "    hemisphere = ''\n",
    "    region = r\n",
    "    print(region)\n",
    "    # selects the subjects with electrodes in your selected region\n",
    "    print(results)\n",
    "    subs = results[results.region == region].subjects.iloc[0]\n",
    "\n",
    "    print(len(subs), 'with electrodes in localization')\n",
    "\n",
    "    # checks that the pairs in that region were actually recorded from\n",
    "    # We only record 128 channels for most of this data\n",
    "    # Localization includes all electrodes (up to 256)\n",
    "    # So this checks that the electrodes are also in pairs, which only shows pairs where\n",
    "    # data was recorded\n",
    "    for sub in subs:\n",
    "        data = get_data_index('r1'); data = data[(data.experiment == 'RepFR1') & (data.subject==sub)]\n",
    "        r = cml.CMLReader(subject=sub, experiment='RepFR1', session = data.session.iloc[0])\n",
    "        loc = r.load(\"localization\")\n",
    "        pairs = r.load('pairs')\n",
    "        loc_p = loc.loc['pairs']\n",
    "        f_loc_p = loc_p[(loc_p['atlases.whole_brain'].str.contains(hemisphere)) & loc_p['atlases.whole_brain'].str.contains(region)]\n",
    "        pairs_filter = []\n",
    "        for labels in f_loc_p.index:\n",
    "            biploar_label = labels[0]+'-'+labels[1]\n",
    "            pairs_filter.append(biploar_label)\n",
    "        pairs = pairs[pairs.label.isin(pairs_filter)]\n",
    "        if pairs.empty:\n",
    "            subs = subs[subs != sub]\n",
    "    print(len(subs), 'with region in localization & pairs')\n",
    "    # print(subs)\n",
    "    # makes lists of hemi and reg as same length as subs array\n",
    "    # this is because Dask requires all of your parameters to have the same shape\n",
    "    hemispheres = []\n",
    "    regions = []\n",
    "    print(subs)\n",
    "    for i in subs:\n",
    "        regions.append(region)\n",
    "        hemispheres.append(hemisphere)\n",
    "    \n",
    "#     client = CMLDask.new_dask_client(\"iEEG_powers\", \"10GB\")\n",
    "#     futures = client.map(get_powers, subs, hemispheres, regions)\n",
    "    # waits until the cluster job is complete\n",
    "#     wait(futures)\n",
    "    # gathers any errors\n",
    "#     power_errors = client.gather(futures)\n",
    "    # shuts down the cluster\n",
    "#     client.shutdown()\n",
    "    # displays errors\n",
    "#     display(power_errors)\n",
    "    # creates new cluster jobs, 1 for each subject, 50GB memory to calculate t-stats\n",
    "    client = CMLDask.new_dask_client(\"iEEG_stats\", \"25GB\")\n",
    "    futures = client.map(power_statistics, subs, hemispheres, regions)\n",
    "    progress(futures)\n",
    "    wait(futures)\n",
    "    ahh = client.gather(futures)\n",
    "    # shuts down client\n",
    "    client.shutdown()\n",
    "    print(r, ahh)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "28c6c44e-0b18-4e74-afb6-a021270e942d",
   "metadata": {},
   "source": [
    "CMLDask.get_exceptions(futures, subs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environmentname",
   "language": "python",
   "name": "environmentname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
